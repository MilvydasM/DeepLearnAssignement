{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "### Final Assignment\n",
    "<br/> by Milvydas Miseviƒçius KT-8/2\n",
    "<br/> Email: milvydas.mi8891@go.kauko.lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "1. Importing data <br/>\n",
    "2. Rescaling the data <br/>\n",
    "3. Building the RNN <br/>\n",
    "4. Training and deployment of the RNN <br/>\n",
    "5. Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "Given a 10-year history of a selected US based company, predict the stock values for the month of August 2019 and compare the actual stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the terminal, download the stock price files from github, or upload them manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " wget https://raw.githubusercontent.com/MilvydasM/DeepLearnAssignement/master/NKE_training_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " wget https://raw.githubusercontent.com/MilvydasM/DeepLearnAssignement/master/NKE_test_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History step is 90 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A few integrals for swapping easily:\n",
    "#History step:\n",
    "hs = 90\n",
    "#RNN settings:\n",
    "#Epoch count:\n",
    "eps = 100\n",
    "#Batch size:\n",
    "bsize = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries that will be used in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>13.7325</td>\n",
       "      <td>14.1325</td>\n",
       "      <td>13.6450</td>\n",
       "      <td>14.0225</td>\n",
       "      <td>10.074034</td>\n",
       "      <td>20059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-31</td>\n",
       "      <td>13.9175</td>\n",
       "      <td>14.4425</td>\n",
       "      <td>13.8900</td>\n",
       "      <td>14.1600</td>\n",
       "      <td>10.172816</td>\n",
       "      <td>21796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>14.2450</td>\n",
       "      <td>14.2700</td>\n",
       "      <td>14.0600</td>\n",
       "      <td>14.1550</td>\n",
       "      <td>10.169227</td>\n",
       "      <td>13509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2009-08-04</td>\n",
       "      <td>14.1150</td>\n",
       "      <td>14.3925</td>\n",
       "      <td>14.0375</td>\n",
       "      <td>14.3850</td>\n",
       "      <td>10.334464</td>\n",
       "      <td>14842800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2009-08-05</td>\n",
       "      <td>14.3850</td>\n",
       "      <td>14.5425</td>\n",
       "      <td>14.1825</td>\n",
       "      <td>14.2550</td>\n",
       "      <td>10.241068</td>\n",
       "      <td>16333200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close  Adj Close    Volume\n",
       "0  2009-07-30  13.7325  14.1325  13.6450  14.0225  10.074034  20059600\n",
       "1  2009-07-31  13.9175  14.4425  13.8900  14.1600  10.172816  21796800\n",
       "2  2009-08-03  14.2450  14.2700  14.0600  14.1550  10.169227  13509600\n",
       "3  2009-08-04  14.1150  14.3925  14.0375  14.3850  10.334464  14842800\n",
       "4  2009-08-05  14.3850  14.5425  14.1825  14.2550  10.241068  16333200"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the dataset\n",
    "#loading the file contents \n",
    "dataset_train = pd.read_csv('NKE_training_set.csv')\n",
    "#Command to show the data\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.7325  ],\n",
       "       [13.9175  ],\n",
       "       [14.245   ],\n",
       "       ...,\n",
       "       [87.440002],\n",
       "       [87.650002],\n",
       "       [86.82    ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a subtable of open values\n",
    "#.values makes this vector a numpy array\n",
    "training_set = dataset_train.iloc[:, 1:2].values \n",
    "#Displaying the table after separation\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling and normalizing the data\n",
    "Rescaling our data on a range from 0 to 1.\n",
    "This needs to be done on both data sets (training set and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a scaler instance to rescale all data ranging from 0.0 to 1.0 \n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an actual training set of scaled values\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00472891],\n",
       "       [0.00715904],\n",
       "       [0.01146104],\n",
       "       ...,\n",
       "       [0.97294016],\n",
       "       [0.97569869],\n",
       "       [0.9647959 ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the training set\n",
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data structures\n",
    "#Grabing the last 90 stock prices in the last 4 and a half months before today\n",
    "X_train = []\n",
    "#Y train stands for todays stock price\n",
    "Y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2517, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the size of our training set\n",
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting from the set date (hs value) because this is the first value that enables us to return to the set value\n",
    "for i in range(hs, 2517): \n",
    "# 0 is the column ID, in this case the only column.    \n",
    "# Placing the last \"hs\" days in a row of X train\n",
    "    X_train.append(training_set_scaled[i-hs:i, 0]) \n",
    "    Y_train.append(training_set_scaled[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00472891, 0.00715904, 0.01146104, ..., 0.03625497, 0.03865227,\n",
       "        0.03871794],\n",
       "       [0.00715904, 0.01146104, 0.00975337, ..., 0.03865227, 0.03871794,\n",
       "        0.03549967],\n",
       "       [0.01146104, 0.00975337, 0.01330006, ..., 0.03871794, 0.03549967,\n",
       "        0.03451447],\n",
       "       ...,\n",
       "       [0.98318612, 0.97372828, 0.97031294, ..., 0.96243143, 0.96256283,\n",
       "        0.9647959 ],\n",
       "       [0.97372828, 0.97031294, 0.94351577, ..., 0.96256283, 0.9647959 ,\n",
       "        0.97294016],\n",
       "       [0.97031294, 0.94351577, 0.89465046, ..., 0.9647959 , 0.97294016,\n",
       "        0.97569869]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The X and Y arrays are converted into NumPy arrays\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "#Displaying the X_train values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping the Matrix\n",
    "\n",
    "NumPy matrices are 3D and basically it is necessary to indicate that our matrix consists of 90 (default) days (X) times complete days in information set (Y) times 1 value per matrix cell (scalar) (Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The information is reshaped and a depth dimension added, making the 3D matrix. A depth=1 is added.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the RNN as a sequence of multiple layers\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 75, return_sequences = True, input_shape =  (X_train.shape[1], 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the argument is the dropout rate to ignore in the layers (20%)\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers  \n",
    "We can add more LSTM layers but along with Dropout regularization to make sure we avoid overfitting! The last layer does not return a sequence because it's connected to the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a second LSTM layer and Dropout regularisation\n",
    "regressor.add(LSTM(units = 75, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a third LSTM layer and Dropout regularisation\n",
    "regressor.add(LSTM(units = 75, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a fourth LSTM layer and Dropout regularisation\n",
    "regressor.add(LSTM(units = 75, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the final LSTM layer and some Dropout regularisation\n",
    "#we removed the return_sequences because we no longer return a \n",
    "#sequence but a value instead\n",
    "regressor.add(LSTM(units = 75))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding an output layer and compiling\n",
    "\n",
    "The output has 1 dimension , i.e. one value to be predicted thus or output fully connected layer has dimensionality = 1.\n",
    "\n",
    "Optimizer: rmsprop is recommended in the Keras documentation. The Adam optimizer is also a powerful choice.\n",
    "Loss function: regression problems take the mean square error as most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output layer (units is set to 1, because the output is a single value - out stock price)\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and deployment\n",
    "\n",
    "Fitting the RNN to the training dataset\n",
    "Using the given dataset X we will train the RNN and compare the predictions with Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2427/2427 [==============================] - 108s 45ms/step - loss: 0.0205\n",
      "Epoch 2/100\n",
      "2427/2427 [==============================] - 92s 38ms/step - loss: 0.0026\n",
      "Epoch 3/100\n",
      "2427/2427 [==============================] - 92s 38ms/step - loss: 0.0025\n",
      "Epoch 4/100\n",
      "2427/2427 [==============================] - 92s 38ms/step - loss: 0.0024\n",
      "Epoch 5/100\n",
      "2427/2427 [==============================] - 116s 48ms/step - loss: 0.0021\n",
      "Epoch 6/100\n",
      "2427/2427 [==============================] - 105s 43ms/step - loss: 0.0021\n",
      "Epoch 7/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0020\n",
      "Epoch 8/100\n",
      "2427/2427 [==============================] - 100s 41ms/step - loss: 0.0020\n",
      "Epoch 9/100\n",
      "2427/2427 [==============================] - 103s 42ms/step - loss: 0.0020\n",
      "Epoch 10/100\n",
      "2427/2427 [==============================] - 103s 43ms/step - loss: 0.0021\n",
      "Epoch 11/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0021\n",
      "Epoch 12/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0018\n",
      "Epoch 13/100\n",
      "2427/2427 [==============================] - 103s 42ms/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0017\n",
      "Epoch 15/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 0.0018\n",
      "Epoch 17/100\n",
      "2427/2427 [==============================] - 103s 42ms/step - loss: 0.0015\n",
      "Epoch 18/100\n",
      "2427/2427 [==============================] - 105s 43ms/step - loss: 0.0015\n",
      "Epoch 19/100\n",
      "2427/2427 [==============================] - 107s 44ms/step - loss: 0.0015\n",
      "Epoch 20/100\n",
      "2427/2427 [==============================] - 107s 44ms/step - loss: 0.0015\n",
      "Epoch 21/100\n",
      "2427/2427 [==============================] - 109s 45ms/step - loss: 0.0015\n",
      "Epoch 22/100\n",
      "2427/2427 [==============================] - 103s 42ms/step - loss: 0.0018\n",
      "Epoch 23/100\n",
      "2427/2427 [==============================] - 99s 41ms/step - loss: 0.0016\n",
      "Epoch 24/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0014\n",
      "Epoch 25/100\n",
      "2427/2427 [==============================] - 105s 43ms/step - loss: 0.0013\n",
      "Epoch 26/100\n",
      "2427/2427 [==============================] - 98s 40ms/step - loss: 0.0013\n",
      "Epoch 27/100\n",
      "2427/2427 [==============================] - 103s 43ms/step - loss: 0.0013\n",
      "Epoch 28/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0013\n",
      "Epoch 29/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0013\n",
      "Epoch 30/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0013\n",
      "Epoch 31/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0012\n",
      "Epoch 33/100\n",
      "2427/2427 [==============================] - 98s 40ms/step - loss: 0.0012\n",
      "Epoch 34/100\n",
      "2427/2427 [==============================] - 98s 40ms/step - loss: 0.0015\n",
      "Epoch 35/100\n",
      "2427/2427 [==============================] - 96s 39ms/step - loss: 0.0012\n",
      "Epoch 36/100\n",
      "2427/2427 [==============================] - 96s 39ms/step - loss: 0.0011\n",
      "Epoch 37/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "2427/2427 [==============================] - 98s 41ms/step - loss: 0.0011\n",
      "Epoch 39/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 9.5750e-04\n",
      "Epoch 40/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0010\n",
      "Epoch 41/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0011\n",
      "Epoch 42/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0010\n",
      "Epoch 43/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0010\n",
      "Epoch 44/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0012\n",
      "Epoch 45/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 0.0010\n",
      "Epoch 46/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 9.1755e-04\n",
      "Epoch 47/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 9.9138e-04\n",
      "Epoch 48/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 9.9672e-04\n",
      "Epoch 49/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0011\n",
      "Epoch 50/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.6786e-04\n",
      "Epoch 51/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0010\n",
      "Epoch 52/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 0.0010\n",
      "Epoch 53/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.6828e-04\n",
      "Epoch 54/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 9.3913e-04\n",
      "Epoch 55/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.7083e-04\n",
      "Epoch 56/100\n",
      "2427/2427 [==============================] - 95s 39ms/step - loss: 9.6590e-04\n",
      "Epoch 57/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.5773e-04\n",
      "Epoch 58/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.6979e-04\n",
      "Epoch 59/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.0039e-04\n",
      "Epoch 60/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.2256e-04\n",
      "Epoch 61/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 9.4075e-04\n",
      "Epoch 62/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 9.1901e-04\n",
      "Epoch 63/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.1322e-04\n",
      "Epoch 64/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 7.9927e-04\n",
      "Epoch 65/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 7.9082e-04\n",
      "Epoch 66/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 8.1698e-04\n",
      "Epoch 67/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 7.8084e-04\n",
      "Epoch 68/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 7.4542e-04\n",
      "Epoch 69/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 0.0010\n",
      "Epoch 70/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 7.6840e-04\n",
      "Epoch 71/100\n",
      "2427/2427 [==============================] - 94s 39ms/step - loss: 8.0388e-04\n",
      "Epoch 72/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 7.7541e-04\n",
      "Epoch 73/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 8.0766e-04\n",
      "Epoch 74/100\n",
      "2427/2427 [==============================] - 93s 38ms/step - loss: 7.5505e-04\n",
      "Epoch 75/100\n",
      "2427/2427 [==============================] - 104s 43ms/step - loss: 8.7108e-04\n",
      "Epoch 76/100\n",
      "2427/2427 [==============================] - 116s 48ms/step - loss: 8.3957e-04\n",
      "Epoch 77/100\n",
      "2427/2427 [==============================] - 111s 46ms/step - loss: 8.4715e-04\n",
      "Epoch 78/100\n",
      "2427/2427 [==============================] - 111s 46ms/step - loss: 6.7001e-04\n",
      "Epoch 79/100\n",
      "2427/2427 [==============================] - 108s 45ms/step - loss: 7.3674e-04\n",
      "Epoch 80/100\n",
      "2427/2427 [==============================] - 111s 46ms/step - loss: 7.7633e-04\n",
      "Epoch 81/100\n",
      "2427/2427 [==============================] - 112s 46ms/step - loss: 7.3096e-04\n",
      "Epoch 82/100\n",
      "2427/2427 [==============================] - 111s 46ms/step - loss: 7.8540e-04\n",
      "Epoch 83/100\n",
      "2427/2427 [==============================] - 106s 44ms/step - loss: 8.3477e-04\n",
      "Epoch 84/100\n",
      "2427/2427 [==============================] - 110s 45ms/step - loss: 7.1560e-04\n",
      "Epoch 85/100\n",
      "2427/2427 [==============================] - 108s 45ms/step - loss: 7.1174e-04\n",
      "Epoch 86/100\n",
      "2427/2427 [==============================] - 117s 48ms/step - loss: 8.6450e-04\n",
      "Epoch 87/100\n",
      "2427/2427 [==============================] - 121s 50ms/step - loss: 7.5610e-04\n",
      "Epoch 88/100\n",
      "2427/2427 [==============================] - 122s 50ms/step - loss: 6.3062e-04\n",
      "Epoch 89/100\n",
      "2427/2427 [==============================] - 120s 50ms/step - loss: 6.8457e-04\n",
      "Epoch 90/100\n",
      "2427/2427 [==============================] - 122s 50ms/step - loss: 7.6971e-04\n",
      "Epoch 91/100\n",
      "2427/2427 [==============================] - 118s 49ms/step - loss: 6.8048e-04\n",
      "Epoch 92/100\n",
      "2427/2427 [==============================] - 121s 50ms/step - loss: 8.9836e-04\n",
      "Epoch 93/100\n",
      "2427/2427 [==============================] - 121s 50ms/step - loss: 7.7272e-04\n",
      "Epoch 94/100\n",
      "2427/2427 [==============================] - 121s 50ms/step - loss: 8.2941e-04\n",
      "Epoch 95/100\n",
      "2427/2427 [==============================] - 120s 49ms/step - loss: 7.1028e-04\n",
      "Epoch 96/100\n",
      "2427/2427 [==============================] - 117s 48ms/step - loss: 6.8287e-04\n",
      "Epoch 97/100\n",
      "2427/2427 [==============================] - 104s 43ms/step - loss: 7.7281e-04\n",
      "Epoch 98/100\n",
      "2427/2427 [==============================] - 102s 42ms/step - loss: 6.9114e-04\n",
      "Epoch 99/100\n",
      "2427/2427 [==============================] - 107s 44ms/step - loss: 7.2899e-04\n",
      "Epoch 100/100\n",
      "2427/2427 [==============================] - 111s 46ms/step - loss: 6.7971e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f205da6bd68>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, Y_train, epochs = int(eps), batch_size = int(bsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>87.089996</td>\n",
       "      <td>87.269997</td>\n",
       "      <td>85.550003</td>\n",
       "      <td>86.029999</td>\n",
       "      <td>85.808327</td>\n",
       "      <td>5818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>85.260002</td>\n",
       "      <td>86.769997</td>\n",
       "      <td>82.699997</td>\n",
       "      <td>83.120003</td>\n",
       "      <td>82.905830</td>\n",
       "      <td>7871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>82.529999</td>\n",
       "      <td>83.239998</td>\n",
       "      <td>80.790001</td>\n",
       "      <td>81.139999</td>\n",
       "      <td>80.930923</td>\n",
       "      <td>8761400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>79.660004</td>\n",
       "      <td>80.050003</td>\n",
       "      <td>78.190002</td>\n",
       "      <td>78.970001</td>\n",
       "      <td>78.766518</td>\n",
       "      <td>8493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>79.849998</td>\n",
       "      <td>81.589996</td>\n",
       "      <td>79.489998</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>81.090515</td>\n",
       "      <td>8664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>80.089996</td>\n",
       "      <td>81.279999</td>\n",
       "      <td>81.070564</td>\n",
       "      <td>6275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>81.809998</td>\n",
       "      <td>83.360001</td>\n",
       "      <td>81.610001</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>82.786133</td>\n",
       "      <td>6208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>83.139999</td>\n",
       "      <td>83.430000</td>\n",
       "      <td>81.320000</td>\n",
       "      <td>81.980003</td>\n",
       "      <td>81.768768</td>\n",
       "      <td>5460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>81.410004</td>\n",
       "      <td>81.949997</td>\n",
       "      <td>81.180000</td>\n",
       "      <td>81.650002</td>\n",
       "      <td>81.439613</td>\n",
       "      <td>3595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>81.169998</td>\n",
       "      <td>84.150002</td>\n",
       "      <td>80.849998</td>\n",
       "      <td>83.320000</td>\n",
       "      <td>83.105309</td>\n",
       "      <td>6896800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>81.239998</td>\n",
       "      <td>81.690002</td>\n",
       "      <td>80.510002</td>\n",
       "      <td>81.029999</td>\n",
       "      <td>80.821205</td>\n",
       "      <td>7266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>80.930000</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>79.440002</td>\n",
       "      <td>79.510002</td>\n",
       "      <td>79.305130</td>\n",
       "      <td>6713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>80.089996</td>\n",
       "      <td>80.559998</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>80.279999</td>\n",
       "      <td>80.073143</td>\n",
       "      <td>5649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.339996</td>\n",
       "      <td>80.830002</td>\n",
       "      <td>81.129997</td>\n",
       "      <td>80.920952</td>\n",
       "      <td>7027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>80.720001</td>\n",
       "      <td>81.230003</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>80.529999</td>\n",
       "      <td>80.322495</td>\n",
       "      <td>5903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>81.940002</td>\n",
       "      <td>82.839996</td>\n",
       "      <td>81.629997</td>\n",
       "      <td>82.739998</td>\n",
       "      <td>82.526802</td>\n",
       "      <td>6454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.720001</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>83.309998</td>\n",
       "      <td>83.095329</td>\n",
       "      <td>5571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>82.019997</td>\n",
       "      <td>82.760002</td>\n",
       "      <td>80.029999</td>\n",
       "      <td>80.440002</td>\n",
       "      <td>80.232735</td>\n",
       "      <td>8497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>81.440002</td>\n",
       "      <td>82.279999</td>\n",
       "      <td>80.739998</td>\n",
       "      <td>82.250000</td>\n",
       "      <td>82.038063</td>\n",
       "      <td>4336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>82.629997</td>\n",
       "      <td>83.180000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.029999</td>\n",
       "      <td>81.818634</td>\n",
       "      <td>3842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>83.589996</td>\n",
       "      <td>81.720001</td>\n",
       "      <td>83.480003</td>\n",
       "      <td>83.264900</td>\n",
       "      <td>4123700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>84.220001</td>\n",
       "      <td>85.769997</td>\n",
       "      <td>84.169998</td>\n",
       "      <td>85.379997</td>\n",
       "      <td>85.159996</td>\n",
       "      <td>5101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>85.699997</td>\n",
       "      <td>85.989998</td>\n",
       "      <td>84.410004</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>5235400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close   Volume\n",
       "0   2019-07-31  87.089996  87.269997  85.550003  86.029999  85.808327  5818200\n",
       "1   2019-08-01  85.260002  86.769997  82.699997  83.120003  82.905830  7871800\n",
       "2   2019-08-02  82.529999  83.239998  80.790001  81.139999  80.930923  8761400\n",
       "3   2019-08-05  79.660004  80.050003  78.190002  78.970001  78.766518  8493300\n",
       "4   2019-08-06  79.849998  81.589996  79.489998  81.300003  81.090515  8664500\n",
       "5   2019-08-07  80.500000  81.820000  80.089996  81.279999  81.070564  6275000\n",
       "6   2019-08-08  81.809998  83.360001  81.610001  83.000000  82.786133  6208900\n",
       "7   2019-08-09  83.139999  83.430000  81.320000  81.980003  81.768768  5460200\n",
       "8   2019-08-12  81.410004  81.949997  81.180000  81.650002  81.439613  3595500\n",
       "9   2019-08-13  81.169998  84.150002  80.849998  83.320000  83.105309  6896800\n",
       "10  2019-08-14  81.239998  81.690002  80.510002  81.029999  80.821205  7266100\n",
       "11  2019-08-15  80.930000  81.300003  79.440002  79.510002  79.305130  6713600\n",
       "12  2019-08-16  80.089996  80.559998  79.250000  80.279999  80.073143  5649000\n",
       "13  2019-08-19  82.000000  82.339996  80.830002  81.129997  80.920952  7027900\n",
       "14  2019-08-20  80.720001  81.230003  79.449997  80.529999  80.322495  5903100\n",
       "15  2019-08-21  81.940002  82.839996  81.629997  82.739998  82.526802  6454200\n",
       "16  2019-08-22  83.000000  83.720001  82.500000  83.309998  83.095329  5571600\n",
       "17  2019-08-23  82.019997  82.760002  80.029999  80.440002  80.232735  8497800\n",
       "18  2019-08-26  81.440002  82.279999  80.739998  82.250000  82.038063  4336000\n",
       "19  2019-08-27  82.629997  83.180000  82.000000  82.029999  81.818634  3842500\n",
       "20  2019-08-28  81.900002  83.589996  81.720001  83.480003  83.264900  4123700\n",
       "21  2019-08-29  84.220001  85.769997  84.169998  85.379997  85.159996  5101900\n",
       "22  2019-08-30  85.699997  85.989998  84.410004  84.500000  84.500000  5235400"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the file we will use for testing the RNN\n",
    "dataset_test = pd.read_csv('NKE_test_set.csv')\n",
    "#displaying the test dataset\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "#displaying the real stock price size\n",
    "real_stock_price.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis = 0 means concatenate the lines (i.e. vertical axis)\n",
    "#both dataset files are joined back into one\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0) \n",
    "#displaying the total dataset size\n",
    "dataset_total.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the test dataset size\n",
    "dataset_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference in the length of the first two gives us \n",
    "#the first day in 2017, and we need to go back 60 days to get the necessary range\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - hs:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94351577],\n",
       "       [0.89465046],\n",
       "       [0.92289248],\n",
       "       [0.92368069],\n",
       "       [0.92683327],\n",
       "       [0.93563427],\n",
       "       [0.94141409],\n",
       "       [0.94088864],\n",
       "       [0.93957508],\n",
       "       [0.93418933],\n",
       "       [0.9540245 ],\n",
       "       [0.94102003],\n",
       "       [0.93064268],\n",
       "       [0.93615972],\n",
       "       [0.93957508],\n",
       "       [0.94482944],\n",
       "       [0.9657154 ],\n",
       "       [0.96716036],\n",
       "       [0.97963938],\n",
       "       [0.99027949],\n",
       "       [0.98489374],\n",
       "       [0.97464779],\n",
       "       [0.97596135],\n",
       "       [0.98555058],\n",
       "       [0.97963938],\n",
       "       [0.98266067],\n",
       "       [0.98410563],\n",
       "       [0.97674957],\n",
       "       [0.95678302],\n",
       "       [0.95271094],\n",
       "       [0.9247315 ],\n",
       "       [0.9148796 ],\n",
       "       [0.90712949],\n",
       "       [0.90423958],\n",
       "       [0.91172702],\n",
       "       [0.89688354],\n",
       "       [0.91172702],\n",
       "       [0.91685   ],\n",
       "       [0.9344521 ],\n",
       "       [0.92131624],\n",
       "       [0.92512565],\n",
       "       [0.91934585],\n",
       "       [0.91448554],\n",
       "       [0.908049  ],\n",
       "       [0.9041082 ],\n",
       "       [0.91264652],\n",
       "       [0.8845358 ],\n",
       "       [0.8610226 ],\n",
       "       [0.84893764],\n",
       "       [0.83895436],\n",
       "       [0.86601429],\n",
       "       [0.90529048],\n",
       "       [0.9109389 ],\n",
       "       [0.9157991 ],\n",
       "       [0.92446882],\n",
       "       [0.92315526],\n",
       "       [0.92092218],\n",
       "       [0.91658733],\n",
       "       [0.92131624],\n",
       "       [0.91908306],\n",
       "       [0.91067613],\n",
       "       [0.92420614],\n",
       "       [0.93957508],\n",
       "       [0.94299043],\n",
       "       [0.9540245 ],\n",
       "       [0.93563427],\n",
       "       [0.91658733],\n",
       "       [0.91369742],\n",
       "       [0.9276214 ],\n",
       "       [0.93996913],\n",
       "       [0.94561756],\n",
       "       [0.9452235 ],\n",
       "       [0.95139737],\n",
       "       [0.95481262],\n",
       "       [0.98160977],\n",
       "       [0.98660146],\n",
       "       [0.9764868 ],\n",
       "       [0.98266067],\n",
       "       [0.9942202 ],\n",
       "       [1.        ],\n",
       "       [0.98581325],\n",
       "       [0.97543591],\n",
       "       [0.97674957],\n",
       "       [0.96138055],\n",
       "       [0.96243143],\n",
       "       [0.96256283],\n",
       "       [0.9647959 ],\n",
       "       [0.97294016],\n",
       "       [0.97569869],\n",
       "       [0.9647959 ],\n",
       "       [0.96834253],\n",
       "       [0.94430399],\n",
       "       [0.90844306],\n",
       "       [0.87074321],\n",
       "       [0.87323895],\n",
       "       [0.88177728],\n",
       "       [0.89898523],\n",
       "       [0.91645593],\n",
       "       [0.89373096],\n",
       "       [0.89057828],\n",
       "       [0.89149779],\n",
       "       [0.8874257 ],\n",
       "       [0.87639153],\n",
       "       [0.90148107],\n",
       "       [0.88466718],\n",
       "       [0.90069294],\n",
       "       [0.91461693],\n",
       "       [0.90174375],\n",
       "       [0.89412501],\n",
       "       [0.90975662],\n",
       "       [0.90016751],\n",
       "       [0.93064268],\n",
       "       [0.9500837 ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we did not use iloc from panda so lets reshape the numpy array for \n",
    "#compatibility: i.e. all the values from input lines to be stacked in one \n",
    "#column. The -1 means that the numpy has no knowledge of how the \n",
    "#values were stored in lines. The 1 means we want to them in one column.\n",
    "\n",
    "inputs = inputs.reshape(-1,1) \n",
    "\n",
    "#applying the feature scaler\n",
    "inputs = sc.transform(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the prediction for the stock prices\n",
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 'hs' from inputs are from training set; start \n",
    "# from 'hs' and get the extra 20, i.e. up to 110\n",
    "for i in range(hs, 113): \n",
    "    X_test.append(inputs[i-hs:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test) # not 3D structure yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 3D structure\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The scaling must be reversed to obtain relevant stock price # outputs\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) \n",
    "#displaying the predicted stock price size\n",
    "predicted_stock_price.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising the results\n",
    "\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Nike Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Nike Stock Price')\n",
    "plt.title('Nike Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Nike Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction lags behind the actual price curve because the model cannot react to fast non-linear changes. Spikes are examples of fast non-linear changes, and there are a few steep ones.  \n",
    "Model reacts pretty well to smooth changes.\n",
    "To receive better results, we can always can add more hidden layers to the network and that would improve the predictions, but will get closer to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
